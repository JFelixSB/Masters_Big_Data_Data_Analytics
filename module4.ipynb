{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MODULE 4 - BIG DATA FUNDAMENTALS",
   "id": "723d71fa18387350"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1.1.1 Data Volume",
   "id": "a139edb6f9e26995"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:33:16.110111Z",
     "start_time": "2025-07-02T19:33:16.105663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ‚îÄ‚îÄ Cell 1: configure Spark env and init findspark ‚îÄ‚îÄ\n",
    "import os\n",
    "\n",
    "# 1) Where you unpacked Spark\n",
    "os.environ['SPARK_HOME'] = '/Users/jfelixsb/spark'\n",
    "\n",
    "# 2) Your JDK path\n",
    "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/jdk-21.jdk/Contents/Home'\n",
    "\n",
    "# 3) Put Spark‚Äôs bin first in PATH\n",
    "os.environ['PATH'] = os.path.join(os.environ['SPARK_HOME'], 'bin') + ':' + os.environ.get('PATH', '')\n",
    "\n",
    "# 4) (Optional) helps PySpark find everything\n",
    "#    Make sure you‚Äôve `pip install findspark` in your venv\n",
    "import findspark\n",
    "\n",
    "findspark.init()"
   ],
   "id": "5a805ad001cc5607",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-02T19:22:36.661872Z",
     "start_time": "2025-07-02T19:22:36.479464Z"
    }
   },
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setAppName(\"FacebookInteractionsCount\") \\\n",
    "    .setMaster(\"local[*]\")\n",
    "\n",
    "# This will either return your already-running sc, or make it fresh\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "# sanity check\n",
    "print(\"Spark v.\", sc._gateway.jvm.org.apache.spark.SPARK_VERSION)\n",
    "\n",
    "data = sc.textFile('example_files/facebook_interactions.txt')\n",
    "\n",
    "elements = data.collect()\n",
    "print(elements)  # Not nice, prints an aray\n",
    "\n",
    "for elem in elements:\n",
    "    print(elem)\n",
    "\n",
    "num_interactions = data.count()\n",
    "\n",
    "print(f'Number of interactions: {num_interactions}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark v. <py4j.java_gateway.JavaPackage object at 0x115cafb50>\n",
      "['userId,postId,interactionType,timestamp', '1,1001,like,2025-07-02T10:00:00Z', '2,1001,comment,2025-07-02T10:01:23Z', '3,1002,share,2025-07-02T10:05:12Z', '4,1003,like,2025-07-02T10:08:45Z', '5,1002,like,2025-07-02T10:09:01Z', '6,1003,comment,2025-07-02T10:12:34Z', '7,1004,share,2025-07-02T10:15:55Z', '8,1001,like,2025-07-02T10:18:20Z', '9,1005,comment,2025-07-02T10:20:11Z', '10,1002,like,2025-07-02T10:22:47Z', '11,1004,like,2025-07-02T10:25:30Z', '12,1005,share,2025-07-02T10:28:05Z']\n",
      "userId,postId,interactionType,timestamp\n",
      "1,1001,like,2025-07-02T10:00:00Z\n",
      "2,1001,comment,2025-07-02T10:01:23Z\n",
      "3,1002,share,2025-07-02T10:05:12Z\n",
      "4,1003,like,2025-07-02T10:08:45Z\n",
      "5,1002,like,2025-07-02T10:09:01Z\n",
      "6,1003,comment,2025-07-02T10:12:34Z\n",
      "7,1004,share,2025-07-02T10:15:55Z\n",
      "8,1001,like,2025-07-02T10:18:20Z\n",
      "9,1005,comment,2025-07-02T10:20:11Z\n",
      "10,1002,like,2025-07-02T10:22:47Z\n",
      "11,1004,like,2025-07-02T10:25:30Z\n",
      "12,1005,share,2025-07-02T10:28:05Z\n",
      "Number of interactions: 13\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a3f64d7d19e14486"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1.1.2 Data Variety",
   "id": "b6aad7d42a98ed03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T20:13:55.862063Z",
     "start_time": "2025-07-02T20:13:55.712338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "print(\"Working directory:\", os.getcwd())\n",
    "!ls -la\n"
   ],
   "id": "f4be1b6d465d3a89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /Users/jfelixsb/PycharmProjects/Masters_Big_Data_Data_Analytics\n",
      "total 1016\r\n",
      "drwxr-xr-x@ 10 jfelixsb  staff     320 Jul  2 16:13 \u001B[34m.\u001B[m\u001B[m\r\n",
      "drwxr-xr-x  15 jfelixsb  staff     480 Jun 13 16:52 \u001B[34m..\u001B[m\u001B[m\r\n",
      "drwxr-xr-x@ 14 jfelixsb  staff     448 Jul  2 15:26 \u001B[34m.git\u001B[m\u001B[m\r\n",
      "drwxr-xr-x@  9 jfelixsb  staff     288 Jul  2 16:13 \u001B[34m.idea\u001B[m\u001B[m\r\n",
      "drwxr-xr-x@ 10 jfelixsb  staff     320 Jul  2 14:46 \u001B[34m.venv\u001B[m\u001B[m\r\n",
      "drwxr-xr-x@  3 jfelixsb  staff      96 Jul  2 15:32 \u001B[34martifacts\u001B[m\u001B[m\r\n",
      "drwxr-xr-x@  7 jfelixsb  staff     224 Jul  2 15:29 \u001B[34mexample_files\u001B[m\u001B[m\r\n",
      "-rw-r--r--@  1 jfelixsb  staff   43581 Jun 14 11:53 module2.ipynb\r\n",
      "-rw-r--r--@  1 jfelixsb  staff  447307 Jun 26 12:26 module3.ipynb\r\n",
      "-rw-r--r--@  1 jfelixsb  staff   20523 Jul  2 16:13 module4.ipynb\r\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T21:07:28.252055Z",
     "start_time": "2025-07-02T21:07:27.974484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# Crear una sesi√≥n Spark\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"TwitterDataAnalysis\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# Leer los datos de Twitter en formato JSON\n",
    "tweets_df = (spark.read\n",
    "             .option(\"multiline\", True)\n",
    "             .json(\"example_files/tweets.json\"))\n",
    "print(tweets_df)\n",
    "tweets_df.printSchema()\n",
    "\n",
    "# 4) Explode the array into separate rows\n",
    "tweets = tweets_df.select(explode(col(\"data\")).alias(\"tweet\"))\n",
    "\n",
    "# 5) Pull out the text field\n",
    "tweets_text = tweets.select(col(\"tweet.text\").alias(\"text\"))\n",
    "\n",
    "# Mostrar los primeros 5 tweets\n",
    "tweets_text.show()\n",
    "\n",
    "# ((tweets_df\n",
    "#  .select(explode(col(\"data\")).alias(\"tweet\"))\n",
    "#  .select(col(\"tweet.text\").alias(\"text\")))\n",
    "#  .show())"
   ],
   "id": "70774abf72632c1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[data: array<struct<id:bigint,likes:bigint,text:string,timestamp:string,user:string>>]\n",
      "root\n",
      " |-- data: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- likes: long (nullable = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- timestamp: string (nullable = true)\n",
      " |    |    |-- user: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Just had the best...|\n",
      "|RT @charlie: Spar...|\n",
      "|Preparing my talk...|\n",
      "|Sunny day in Mont...|\n",
      "|Does anyone know ...|\n",
      "|Deploying my firs...|\n",
      "|Lunch break! üçî #...|\n",
      "|Debugging streami...|\n",
      "|Schema evolution ...|\n",
      "|Wrapping up today...|\n",
      "+--------------------+\n",
      "\n",
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Just had the best...|\n",
      "|RT @charlie: Spar...|\n",
      "|Preparing my talk...|\n",
      "|Sunny day in Mont...|\n",
      "|Does anyone know ...|\n",
      "|Deploying my firs...|\n",
      "|Lunch break! üçî #...|\n",
      "|Debugging streami...|\n",
      "|Schema evolution ...|\n",
      "|Wrapping up today...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "48b48b339b34edbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1.1.5 Data Quality",
   "id": "b6359deaecba2738"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T22:04:33.787260Z",
     "start_time": "2025-07-02T22:04:33.781091Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "ad7d560d2477be7c",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T02:35:39.495745Z",
     "start_time": "2025-07-03T02:35:39.480460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv('example_files/data_quality_sales.csv')\n",
    "\n",
    "print('Initial df\\n', df)\n",
    "\n",
    "# Corregir los errores de entrada de datos\n",
    "df['email'] = df['email'].str.lower()\n",
    "df['email'] = df['email'].fillna('No Data')\n",
    "print('\\nLowercasing emails\\n', df)\n",
    "\n",
    "df['sales'] = pd.to_numeric(df['sales'], errors='coerce')\n",
    "print('\\nTurning non-numeric cells into NaN\\n', df)\n",
    "\n",
    "# Imputar los valores faltantes con la media\n",
    "# Important to make sure to only compute the mean for the numeric cols\n",
    "df['sales'] = df['sales'].fillna(df['sales'].mean())\n",
    "df['temperature'] = df['temperature'].fillna(df['temperature'].mean())\n",
    "df['humidity'] = df['humidity'].fillna(df['humidity'].mean())\n",
    "print('\\nReplacing the NaN on the numeric cols by the mean of that col\\n', df)\n",
    "\n",
    "\n",
    "# Normalizar las fechas a un formato com√∫n\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "# df['date'] = df['date'].fillna('No Data')\n",
    "print('\\nReplacing missing dates by NaT\\n', df)\n",
    "\n",
    "# Seleccionar las caracter√≠sticas relevantes\n",
    "# df = df['date', 'sales', 'temperature', 'humidity']\n",
    "print('\\nFinal version\\n', df[['date', 'email', 'sales', 'temperature']])"
   ],
   "id": "53c46771fff86f7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial df\n",
      "            date                 email         sales  temperature  humidity\n",
      "0    2025-07-01     Alice@example.COM           100         22.5      0.30\n",
      "1    2025-07-02       BOB@Example.com         200.5         21.0       NaN\n",
      "2    2025-07-03   Charlie@Example.COM           NaN         20.0      0.40\n",
      "3  invalid_date  danielle@Example.com  not a number         22.0      0.45\n",
      "4    2025-07-05                   NaN         150.0         24.0      0.50\n",
      "\n",
      "Lowercasing emails\n",
      "            date                 email         sales  temperature  humidity\n",
      "0    2025-07-01     alice@example.com           100         22.5      0.30\n",
      "1    2025-07-02       bob@example.com         200.5         21.0       NaN\n",
      "2    2025-07-03   charlie@example.com           NaN         20.0      0.40\n",
      "3  invalid_date  danielle@example.com  not a number         22.0      0.45\n",
      "4    2025-07-05               No Data         150.0         24.0      0.50\n",
      "\n",
      "Turning non-numeric cells into NaN\n",
      "            date                 email  sales  temperature  humidity\n",
      "0    2025-07-01     alice@example.com  100.0         22.5      0.30\n",
      "1    2025-07-02       bob@example.com  200.5         21.0       NaN\n",
      "2    2025-07-03   charlie@example.com    NaN         20.0      0.40\n",
      "3  invalid_date  danielle@example.com    NaN         22.0      0.45\n",
      "4    2025-07-05               No Data  150.0         24.0      0.50\n",
      "\n",
      "Replacing the NaN on the numeric cols by the mean of that col\n",
      "            date                 email       sales  temperature  humidity\n",
      "0    2025-07-01     alice@example.com  100.000000         22.5    0.3000\n",
      "1    2025-07-02       bob@example.com  200.500000         21.0    0.4125\n",
      "2    2025-07-03   charlie@example.com  150.166667         20.0    0.4000\n",
      "3  invalid_date  danielle@example.com  150.166667         22.0    0.4500\n",
      "4    2025-07-05               No Data  150.000000         24.0    0.5000\n",
      "\n",
      "Replacing missing dates by NaT\n",
      "         date                 email       sales  temperature  humidity\n",
      "0 2025-07-01     alice@example.com  100.000000         22.5    0.3000\n",
      "1 2025-07-02       bob@example.com  200.500000         21.0    0.4125\n",
      "2 2025-07-03   charlie@example.com  150.166667         20.0    0.4000\n",
      "3        NaT  danielle@example.com  150.166667         22.0    0.4500\n",
      "4 2025-07-05               No Data  150.000000         24.0    0.5000\n",
      "\n",
      "Final version\n",
      "         date                 email       sales  temperature\n",
      "0 2025-07-01     alice@example.com  100.000000         22.5\n",
      "1 2025-07-02       bob@example.com  200.500000         21.0\n",
      "2 2025-07-03   charlie@example.com  150.166667         20.0\n",
      "3        NaT  danielle@example.com  150.166667         22.0\n",
      "4 2025-07-05               No Data  150.000000         24.0\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f14e88709364ee7b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
